{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W266 Final Project\n",
    "## Ehsan Yousefzadeh \n",
    "## Summer 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ehsanyousefzadeh/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding nltk.tree.Tree pretty-printing to use custom GraphViz.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os, sys, re, json, time, datetime, shutil\n",
    "import itertools, collections\n",
    "from importlib import reload\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# NLTK \n",
    "import nltk\n",
    "\n",
    "# NumPy, Pandas and TensorFlow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.8\"))\n",
    "import collections\n",
    "\n",
    "#SKlearn \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Helper libraries\n",
    "from w266_common import utils, vocabulary, tf_embed_viz, treeviz\n",
    "from w266_common import patched_numpy_io\n",
    "# Code for this assignment\n",
    "import sst, models, models_test\n",
    "\n",
    "# Monkey-patch NLTK with better Tree display that works on Cloud or other display-less server.\n",
    "print(\"Overriding nltk.tree.Tree pretty-printing to use custom GraphViz.\")\n",
    "treeviz.monkey_patch(nltk.tree.Tree, node_style_fn=sst.sst_node_style, format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scotch_data = pd.read_csv('./scotch_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>review.point</th>\n",
       "      <th>price</th>\n",
       "      <th>currency</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Johnnie Walker Blue Label, 40%</td>\n",
       "      <td>Blended Scotch Whisky</td>\n",
       "      <td>97</td>\n",
       "      <td>225</td>\n",
       "      <td>$</td>\n",
       "      <td>Magnificently powerful and intense. Caramels, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Black Bowmore, 1964 vintage, 42 year old, 40.5%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>97</td>\n",
       "      <td>4500.00</td>\n",
       "      <td>$</td>\n",
       "      <td>What impresses me most is how this whisky evol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bowmore 46 year old (distilled 1964), 42.9%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>97</td>\n",
       "      <td>13500.00</td>\n",
       "      <td>$</td>\n",
       "      <td>There have been some legendary Bowmores from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Compass Box The General, 53.4%</td>\n",
       "      <td>Blended Malt Scotch Whisky</td>\n",
       "      <td>96</td>\n",
       "      <td>325</td>\n",
       "      <td>$</td>\n",
       "      <td>With a name inspired by a 1926 Buster Keaton m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Chivas Regal Ultis, 40%</td>\n",
       "      <td>Blended Malt Scotch Whisky</td>\n",
       "      <td>96</td>\n",
       "      <td>160</td>\n",
       "      <td>$</td>\n",
       "      <td>Captivating, enticing, and wonderfully charmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Ardbeg Corryvreckan, 57.1%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>96</td>\n",
       "      <td>85.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Powerful, muscular, well-textured, and invigor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Gold Bowmore, 1964 vintage, 42.4%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>96</td>\n",
       "      <td>6250.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Deep gold color. Surprisingly lively on the no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Bowmore, 40 year old, 44.8%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>96</td>\n",
       "      <td>11000.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Definitely showing its age, but not in a bad w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>The Dalmore, 50 year old, 52.8%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>96</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>$</td>\n",
       "      <td>The Dalmore is one of a handful of whiskies th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Glenfarclas Family Casks 1954 Cask #1260, 47.2%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>96</td>\n",
       "      <td>3360</td>\n",
       "      <td>$</td>\n",
       "      <td>A rich amber color and elegantly oxidized note...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>The Glenlivet Cellar Collection, 1969 vintage,...</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>96</td>\n",
       "      <td>750.00</td>\n",
       "      <td>$</td>\n",
       "      <td>It’s great that Glenlivet releases whiskies un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Macallan 1976 Vintage, 29 year old, cask #1135...</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>96</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Classic sherry cask-aged Macallan. Antique amb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>The Last Drop (distilled at Lochside) 1972 (ca...</td>\n",
       "      <td>Grain Scotch Whisky</td>\n",
       "      <td>96</td>\n",
       "      <td>3108</td>\n",
       "      <td>$</td>\n",
       "      <td>A remarkable beauty from the Angus town of Mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Compass Box Flaming Heart (10th Anniversary bo...</td>\n",
       "      <td>Blended Malt Scotch Whisky</td>\n",
       "      <td>95</td>\n",
       "      <td>105.00</td>\n",
       "      <td>$</td>\n",
       "      <td>A marriage of three different single malts, ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Compass Box The Peat Monster 10th Anniversary ...</td>\n",
       "      <td>Blended Scotch Whisky</td>\n",
       "      <td>95</td>\n",
       "      <td>120</td>\n",
       "      <td>$</td>\n",
       "      <td>As you’d expect, solid peat is the first thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Johnnie Walker Blue Anniversary, 60%</td>\n",
       "      <td>Blended Scotch Whisky</td>\n",
       "      <td>95</td>\n",
       "      <td>3500.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Formulated to celebrate the 200th anniversary ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Chivas, 18 year old, 40%</td>\n",
       "      <td>Blended Scotch Whisky</td>\n",
       "      <td>95</td>\n",
       "      <td>70.00</td>\n",
       "      <td>$</td>\n",
       "      <td>An essay in balance on both the aroma and pala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Ardbeg, 1974 Vintage, Cask #3145, 49.9%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>95</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Cask #3145 is the lighter in color, and the sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Ardbeg Uigeadail, 54.2%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>95</td>\n",
       "      <td>70.00</td>\n",
       "      <td>$</td>\n",
       "      <td>With the Ardbeg 17 year old off the market, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Balvenie 1973 43 year old, 46.6%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>95</td>\n",
       "      <td>$15,000 or $60,000/set</td>\n",
       "      <td>$</td>\n",
       "      <td>This expression was matured in a European oak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Bowmore 50 year old (distilled 1961), 40.7%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>95</td>\n",
       "      <td>26650</td>\n",
       "      <td>$</td>\n",
       "      <td>The whisky is sensational, a glorious mix of g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Brora, 30 year old, 55.7%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>95</td>\n",
       "      <td>400.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Astonishingly fresh and clean for 30 years in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Lombard 'Jewels of Scotland' (distilled at Bro...</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>95</td>\n",
       "      <td>200.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Bottled in 2004, but just recently put in circ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Brora, 30 year old (2009 Release), 53.2%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>95</td>\n",
       "      <td>400.00</td>\n",
       "      <td>$</td>\n",
       "      <td>This whisky has all the positive aspects of a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Brora 2010, 54.3%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>95</td>\n",
       "      <td>455.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Though Brora has acquired cult status, it has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Brora 35 year old, 49.9%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>95</td>\n",
       "      <td>750</td>\n",
       "      <td>$</td>\n",
       "      <td>Maturation of this 1978 distillate has taken p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Glenfarclas 1968 Vintage, 43% ABV</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>95</td>\n",
       "      <td>200.00</td>\n",
       "      <td>$</td>\n",
       "      <td>It has been quite a while since we’ve seen a n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Glenfarclas, 40 year old, 46%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>95</td>\n",
       "      <td>460.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Glenfarclas has a proven track record for agin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Glenglassaugh, 40 year old, 44.6%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>95</td>\n",
       "      <td>2525.00</td>\n",
       "      <td>$</td>\n",
       "      <td>An excellent example of an ultra-mature, sherr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>The Glenlivet Cellar Collection, 1973 vintage,...</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>95</td>\n",
       "      <td>1250.00</td>\n",
       "      <td>$</td>\n",
       "      <td>A marriage of three casks, one of them an ex-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>2218</td>\n",
       "      <td>The Arran Malt, 12 year old, 46%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>77</td>\n",
       "      <td>50.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Nice to see Arran making it to 12 years old. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>2219</td>\n",
       "      <td>Auchentoshan 1962, 41 year old, 40.3%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>77</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>$</td>\n",
       "      <td>This whisky comes from two bourbon casks, prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>2220</td>\n",
       "      <td>Benromach, Tokaji Finish, 45%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>77</td>\n",
       "      <td>50.00</td>\n",
       "      <td>$</td>\n",
       "      <td>A very peculiar whisky. It’s interesting in so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>2221</td>\n",
       "      <td>Signatory (distilled at Bunnahabhain), cask #5...</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>77</td>\n",
       "      <td>45.00</td>\n",
       "      <td>$</td>\n",
       "      <td>The owners of Bunnahabhain are making a peated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>2222</td>\n",
       "      <td>Cragganmore 21 year old, 56%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>77</td>\n",
       "      <td>205.00</td>\n",
       "      <td>$</td>\n",
       "      <td>The lightness of the hue suggests a very slow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>2223</td>\n",
       "      <td>Glenrothes 1996 Editor’s Cask #9973, 57%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>77</td>\n",
       "      <td>375.00</td>\n",
       "      <td>$</td>\n",
       "      <td>The second of the duo — destined for the U.S. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>2224</td>\n",
       "      <td>Master of Malt Reference Series I, 47.5%</td>\n",
       "      <td>Blended Malt Scotch Whisky</td>\n",
       "      <td>77</td>\n",
       "      <td>62</td>\n",
       "      <td>$</td>\n",
       "      <td>A predominantly young blended malt heads up th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>2225</td>\n",
       "      <td>Grand Macnish 150th Anniversary Edition, 40%</td>\n",
       "      <td>Blended Scotch Whisky</td>\n",
       "      <td>77</td>\n",
       "      <td>18</td>\n",
       "      <td>$</td>\n",
       "      <td>Robert McNish conceived his recipe for a light...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>2226</td>\n",
       "      <td>H5 Iced Single Grain, 40%</td>\n",
       "      <td>Single Grain Whisky</td>\n",
       "      <td>77</td>\n",
       "      <td>22</td>\n",
       "      <td>$</td>\n",
       "      <td>Boldly, this is naturally colored (barely colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>2227</td>\n",
       "      <td>The Lost Distillery Company Auchnagie (batch 2...</td>\n",
       "      <td>Blended Scotch Whisky</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>$</td>\n",
       "      <td>Auchnagie (1812–1911) was a southern Highland ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>2228</td>\n",
       "      <td>Clansman, 40%</td>\n",
       "      <td>Blended Scotch Whisky</td>\n",
       "      <td>77</td>\n",
       "      <td>14</td>\n",
       "      <td>$</td>\n",
       "      <td>This Highland blend has a nose of lemon peel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>2229</td>\n",
       "      <td>Douglas Laing Old Particular (distilled at Por...</td>\n",
       "      <td>Single Grain Whisky</td>\n",
       "      <td>77</td>\n",
       "      <td>129</td>\n",
       "      <td>$</td>\n",
       "      <td>Squished rosehip, nuttiness, and seasoned wood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>2230</td>\n",
       "      <td>Loch Lomond Original, 40%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>76</td>\n",
       "      <td>40</td>\n",
       "      <td>$</td>\n",
       "      <td>Since a change of ownership in 2014, the Loch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>2231</td>\n",
       "      <td>Knockando 12 year old, 43%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>76</td>\n",
       "      <td>48.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Since Diageo has included Knockando in its Spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>2232</td>\n",
       "      <td>MacNaMara Blended, 40%</td>\n",
       "      <td>Blended Scotch Whisky</td>\n",
       "      <td>76</td>\n",
       "      <td>35</td>\n",
       "      <td>$</td>\n",
       "      <td>This amber-colored blend from the Gaelic Whisk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>2233</td>\n",
       "      <td>Robert Burns Single Malt, 40%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>75</td>\n",
       "      <td>40.00</td>\n",
       "      <td>$</td>\n",
       "      <td>This Robert Burns World Federation Arran Singl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>2234</td>\n",
       "      <td>Edradour Bordeaux Finish, 11 year old, 55.8%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>75</td>\n",
       "      <td>80.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Citrus peel, light maple syrup, and almonds, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>2235</td>\n",
       "      <td>Knockando 25 year old Special Release 2011, 43%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>75</td>\n",
       "      <td>220.00</td>\n",
       "      <td>$</td>\n",
       "      <td>What a contrast with the standard bottling. He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>2236</td>\n",
       "      <td>Benromach Organic, 43%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>74</td>\n",
       "      <td>75.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Huge oak impact for such a young whisky. Fresh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>2237</td>\n",
       "      <td>The Macallan Lalique Decanter, 55 year old, 40.1%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>74</td>\n",
       "      <td>12000.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Deep, thick nose, with sappy oak, dried citrus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>2238</td>\n",
       "      <td>Signatory (distilled at Kinclaith), Cask #3014...</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>73</td>\n",
       "      <td>1700.00</td>\n",
       "      <td>$</td>\n",
       "      <td>This Lowland distillery only operated from 195...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>2239</td>\n",
       "      <td>Gordon &amp; MacPhail (distilled at Port Ellen), 1...</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>73</td>\n",
       "      <td>250.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Port Ellen is going to just keep getting rarer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>2240</td>\n",
       "      <td>Benromach Origins, Batch #1, 1999 vintage, 50%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>72</td>\n",
       "      <td>85.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Origins is Benromach’s new program to highligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>2241</td>\n",
       "      <td>Distillery Select 'Croftengea' (distilled at L...</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>72</td>\n",
       "      <td>60.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Quite pale in color. Very youthful and naked, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>2242</td>\n",
       "      <td>Tomintoul, 'With a peaty tang', 40%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>72</td>\n",
       "      <td>45.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Youthful, and somewhat brooding for a Tomintou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2243</td>\n",
       "      <td>Duncan Taylor (distilled at Cameronbridge), Ca...</td>\n",
       "      <td>Grain Scotch Whisky</td>\n",
       "      <td>72</td>\n",
       "      <td>125.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Its best attributes are vanilla, toasted cocon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>2244</td>\n",
       "      <td>Distillery Select 'Craiglodge' (distilled at L...</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>71</td>\n",
       "      <td>60.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Aged in a sherry cask, which adds sweet notes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>2245</td>\n",
       "      <td>Edradour Barolo Finish, 11 year old, 57.1%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>70</td>\n",
       "      <td>80.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Earthy, fleshy notes with brooding grape notes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>2246</td>\n",
       "      <td>Highland Park, Cask #7380, 1981 vintage, 25 ye...</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>70</td>\n",
       "      <td>225.00</td>\n",
       "      <td>$</td>\n",
       "      <td>The sherry is very dominant and cloying, which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>2247</td>\n",
       "      <td>Distillery Select 'Inchmoan' (distilled at Loc...</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>63</td>\n",
       "      <td>60.00</td>\n",
       "      <td>$</td>\n",
       "      <td>Fiery peat kiln smoke, tar, and ripe barley on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2247 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               name  \\\n",
       "0              1                     Johnnie Walker Blue Label, 40%   \n",
       "1              2    Black Bowmore, 1964 vintage, 42 year old, 40.5%   \n",
       "2              3        Bowmore 46 year old (distilled 1964), 42.9%   \n",
       "3              4                     Compass Box The General, 53.4%   \n",
       "4              5                            Chivas Regal Ultis, 40%   \n",
       "5              6                         Ardbeg Corryvreckan, 57.1%   \n",
       "6              7                 Gold Bowmore, 1964 vintage, 42.4%    \n",
       "7              8                        Bowmore, 40 year old, 44.8%   \n",
       "8              9                    The Dalmore, 50 year old, 52.8%   \n",
       "9             10    Glenfarclas Family Casks 1954 Cask #1260, 47.2%   \n",
       "10            11  The Glenlivet Cellar Collection, 1969 vintage,...   \n",
       "11            12  Macallan 1976 Vintage, 29 year old, cask #1135...   \n",
       "12            13  The Last Drop (distilled at Lochside) 1972 (ca...   \n",
       "13            14  Compass Box Flaming Heart (10th Anniversary bo...   \n",
       "14            15  Compass Box The Peat Monster 10th Anniversary ...   \n",
       "15            16               Johnnie Walker Blue Anniversary, 60%   \n",
       "16            17                           Chivas, 18 year old, 40%   \n",
       "17            18            Ardbeg, 1974 Vintage, Cask #3145, 49.9%   \n",
       "18            19                            Ardbeg Uigeadail, 54.2%   \n",
       "19            20                   Balvenie 1973 43 year old, 46.6%   \n",
       "20            21        Bowmore 50 year old (distilled 1961), 40.7%   \n",
       "21            22                          Brora, 30 year old, 55.7%   \n",
       "22            23  Lombard 'Jewels of Scotland' (distilled at Bro...   \n",
       "23            24           Brora, 30 year old (2009 Release), 53.2%   \n",
       "24            25                                  Brora 2010, 54.3%   \n",
       "25            26                           Brora 35 year old, 49.9%   \n",
       "26            27                  Glenfarclas 1968 Vintage, 43% ABV   \n",
       "27            28                      Glenfarclas, 40 year old, 46%   \n",
       "28            29                  Glenglassaugh, 40 year old, 44.6%   \n",
       "29            30  The Glenlivet Cellar Collection, 1973 vintage,...   \n",
       "...          ...                                                ...   \n",
       "2217        2218                   The Arran Malt, 12 year old, 46%   \n",
       "2218        2219              Auchentoshan 1962, 41 year old, 40.3%   \n",
       "2219        2220                      Benromach, Tokaji Finish, 45%   \n",
       "2220        2221  Signatory (distilled at Bunnahabhain), cask #5...   \n",
       "2221        2222                       Cragganmore 21 year old, 56%   \n",
       "2222        2223           Glenrothes 1996 Editor’s Cask #9973, 57%   \n",
       "2223        2224           Master of Malt Reference Series I, 47.5%   \n",
       "2224        2225       Grand Macnish 150th Anniversary Edition, 40%   \n",
       "2225        2226                          H5 Iced Single Grain, 40%   \n",
       "2226        2227  The Lost Distillery Company Auchnagie (batch 2...   \n",
       "2227        2228                                      Clansman, 40%   \n",
       "2228        2229  Douglas Laing Old Particular (distilled at Por...   \n",
       "2229        2230                          Loch Lomond Original, 40%   \n",
       "2230        2231                         Knockando 12 year old, 43%   \n",
       "2231        2232                             MacNaMara Blended, 40%   \n",
       "2232        2233                      Robert Burns Single Malt, 40%   \n",
       "2233        2234       Edradour Bordeaux Finish, 11 year old, 55.8%   \n",
       "2234        2235    Knockando 25 year old Special Release 2011, 43%   \n",
       "2235        2236                             Benromach Organic, 43%   \n",
       "2236        2237  The Macallan Lalique Decanter, 55 year old, 40.1%   \n",
       "2237        2238  Signatory (distilled at Kinclaith), Cask #3014...   \n",
       "2238        2239  Gordon & MacPhail (distilled at Port Ellen), 1...   \n",
       "2239        2240     Benromach Origins, Batch #1, 1999 vintage, 50%   \n",
       "2240        2241  Distillery Select 'Croftengea' (distilled at L...   \n",
       "2241        2242                Tomintoul, 'With a peaty tang', 40%   \n",
       "2242        2243  Duncan Taylor (distilled at Cameronbridge), Ca...   \n",
       "2243        2244  Distillery Select 'Craiglodge' (distilled at L...   \n",
       "2244        2245         Edradour Barolo Finish, 11 year old, 57.1%   \n",
       "2245        2246  Highland Park, Cask #7380, 1981 vintage, 25 ye...   \n",
       "2246        2247  Distillery Select 'Inchmoan' (distilled at Loc...   \n",
       "\n",
       "                        category  review.point                   price  \\\n",
       "0          Blended Scotch Whisky            97                     225   \n",
       "1             Single Malt Scotch            97                 4500.00   \n",
       "2             Single Malt Scotch            97                13500.00   \n",
       "3     Blended Malt Scotch Whisky            96                     325   \n",
       "4     Blended Malt Scotch Whisky            96                     160   \n",
       "5             Single Malt Scotch            96                   85.00   \n",
       "6             Single Malt Scotch            96                 6250.00   \n",
       "7             Single Malt Scotch            96                11000.00   \n",
       "8             Single Malt Scotch            96                 1500.00   \n",
       "9             Single Malt Scotch            96                    3360   \n",
       "10            Single Malt Scotch            96                  750.00   \n",
       "11            Single Malt Scotch            96                 1500.00   \n",
       "12           Grain Scotch Whisky            96                    3108   \n",
       "13    Blended Malt Scotch Whisky            95                  105.00   \n",
       "14         Blended Scotch Whisky            95                     120   \n",
       "15         Blended Scotch Whisky            95                 3500.00   \n",
       "16         Blended Scotch Whisky            95                   70.00   \n",
       "17            Single Malt Scotch            95                20000.00   \n",
       "18            Single Malt Scotch            95                   70.00   \n",
       "19            Single Malt Scotch            95  $15,000 or $60,000/set   \n",
       "20            Single Malt Scotch            95                   26650   \n",
       "21            Single Malt Scotch            95                  400.00   \n",
       "22            Single Malt Scotch            95                  200.00   \n",
       "23            Single Malt Scotch            95                  400.00   \n",
       "24            Single Malt Scotch            95                  455.00   \n",
       "25            Single Malt Scotch            95                     750   \n",
       "26            Single Malt Scotch            95                  200.00   \n",
       "27            Single Malt Scotch            95                  460.00   \n",
       "28            Single Malt Scotch            95                 2525.00   \n",
       "29            Single Malt Scotch            95                 1250.00   \n",
       "...                          ...           ...                     ...   \n",
       "2217          Single Malt Scotch            77                   50.00   \n",
       "2218          Single Malt Scotch            77                 2000.00   \n",
       "2219          Single Malt Scotch            77                   50.00   \n",
       "2220          Single Malt Scotch            77                   45.00   \n",
       "2221          Single Malt Scotch            77                  205.00   \n",
       "2222          Single Malt Scotch            77                  375.00   \n",
       "2223  Blended Malt Scotch Whisky            77                      62   \n",
       "2224       Blended Scotch Whisky            77                      18   \n",
       "2225         Single Grain Whisky            77                      22   \n",
       "2226       Blended Scotch Whisky            77                      65   \n",
       "2227       Blended Scotch Whisky            77                      14   \n",
       "2228         Single Grain Whisky            77                     129   \n",
       "2229          Single Malt Scotch            76                      40   \n",
       "2230          Single Malt Scotch            76                   48.00   \n",
       "2231       Blended Scotch Whisky            76                      35   \n",
       "2232          Single Malt Scotch            75                   40.00   \n",
       "2233          Single Malt Scotch            75                   80.00   \n",
       "2234          Single Malt Scotch            75                  220.00   \n",
       "2235          Single Malt Scotch            74                   75.00   \n",
       "2236          Single Malt Scotch            74                12000.00   \n",
       "2237          Single Malt Scotch            73                 1700.00   \n",
       "2238          Single Malt Scotch            73                  250.00   \n",
       "2239          Single Malt Scotch            72                   85.00   \n",
       "2240          Single Malt Scotch            72                   60.00   \n",
       "2241          Single Malt Scotch            72                   45.00   \n",
       "2242         Grain Scotch Whisky            72                  125.00   \n",
       "2243          Single Malt Scotch            71                   60.00   \n",
       "2244          Single Malt Scotch            70                   80.00   \n",
       "2245          Single Malt Scotch            70                  225.00   \n",
       "2246          Single Malt Scotch            63                   60.00   \n",
       "\n",
       "     currency                                        description  \n",
       "0           $  Magnificently powerful and intense. Caramels, ...  \n",
       "1           $  What impresses me most is how this whisky evol...  \n",
       "2           $  There have been some legendary Bowmores from t...  \n",
       "3           $  With a name inspired by a 1926 Buster Keaton m...  \n",
       "4           $  Captivating, enticing, and wonderfully charmin...  \n",
       "5           $  Powerful, muscular, well-textured, and invigor...  \n",
       "6           $  Deep gold color. Surprisingly lively on the no...  \n",
       "7           $  Definitely showing its age, but not in a bad w...  \n",
       "8           $  The Dalmore is one of a handful of whiskies th...  \n",
       "9           $  A rich amber color and elegantly oxidized note...  \n",
       "10          $  It’s great that Glenlivet releases whiskies un...  \n",
       "11          $  Classic sherry cask-aged Macallan. Antique amb...  \n",
       "12          $  A remarkable beauty from the Angus town of Mon...  \n",
       "13          $  A marriage of three different single malts, ag...  \n",
       "14          $  As you’d expect, solid peat is the first thing...  \n",
       "15          $  Formulated to celebrate the 200th anniversary ...  \n",
       "16          $  An essay in balance on both the aroma and pala...  \n",
       "17          $  Cask #3145 is the lighter in color, and the sw...  \n",
       "18          $  With the Ardbeg 17 year old off the market, it...  \n",
       "19          $  This expression was matured in a European oak ...  \n",
       "20          $  The whisky is sensational, a glorious mix of g...  \n",
       "21          $  Astonishingly fresh and clean for 30 years in ...  \n",
       "22          $  Bottled in 2004, but just recently put in circ...  \n",
       "23          $  This whisky has all the positive aspects of a ...  \n",
       "24          $  Though Brora has acquired cult status, it has ...  \n",
       "25          $  Maturation of this 1978 distillate has taken p...  \n",
       "26          $  It has been quite a while since we’ve seen a n...  \n",
       "27          $  Glenfarclas has a proven track record for agin...  \n",
       "28          $  An excellent example of an ultra-mature, sherr...  \n",
       "29          $  A marriage of three casks, one of them an ex-s...  \n",
       "...       ...                                                ...  \n",
       "2217        $  Nice to see Arran making it to 12 years old. C...  \n",
       "2218        $  This whisky comes from two bourbon casks, prod...  \n",
       "2219        $  A very peculiar whisky. It’s interesting in so...  \n",
       "2220        $  The owners of Bunnahabhain are making a peated...  \n",
       "2221        $  The lightness of the hue suggests a very slow ...  \n",
       "2222        $  The second of the duo — destined for the U.S. ...  \n",
       "2223        $  A predominantly young blended malt heads up th...  \n",
       "2224        $  Robert McNish conceived his recipe for a light...  \n",
       "2225        $  Boldly, this is naturally colored (barely colo...  \n",
       "2226        $  Auchnagie (1812–1911) was a southern Highland ...  \n",
       "2227        $  This Highland blend has a nose of lemon peel, ...  \n",
       "2228        $  Squished rosehip, nuttiness, and seasoned wood...  \n",
       "2229        $  Since a change of ownership in 2014, the Loch ...  \n",
       "2230        $  Since Diageo has included Knockando in its Spe...  \n",
       "2231        $  This amber-colored blend from the Gaelic Whisk...  \n",
       "2232        $  This Robert Burns World Federation Arran Singl...  \n",
       "2233        $  Citrus peel, light maple syrup, and almonds, w...  \n",
       "2234        $  What a contrast with the standard bottling. He...  \n",
       "2235        $  Huge oak impact for such a young whisky. Fresh...  \n",
       "2236        $  Deep, thick nose, with sappy oak, dried citrus...  \n",
       "2237        $  This Lowland distillery only operated from 195...  \n",
       "2238        $  Port Ellen is going to just keep getting rarer...  \n",
       "2239        $  Origins is Benromach’s new program to highligh...  \n",
       "2240        $  Quite pale in color. Very youthful and naked, ...  \n",
       "2241        $  Youthful, and somewhat brooding for a Tomintou...  \n",
       "2242        $  Its best attributes are vanilla, toasted cocon...  \n",
       "2243        $  Aged in a sherry cask, which adds sweet notes ...  \n",
       "2244        $  Earthy, fleshy notes with brooding grape notes...  \n",
       "2245        $  The sherry is very dominant and cloying, which...  \n",
       "2246        $  Fiery peat kiln smoke, tar, and ripe barley on...  \n",
       "\n",
       "[2247 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scotch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scotch_data = scotch_data.drop(scotch_data.index[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scotch_data = scotch_data[scotch_data.price != '60,000/set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scotch_data = scotch_data[scotch_data.price != '44/liter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scotch_y = scotch_data.price.replace({',':''},regex=True).apply(pd.to_numeric,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scotch_y = scotch_y.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scotch_y = scotch_y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531.0312360553324"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scotch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scotch_y1 = []\n",
    "\n",
    "for i in scotch_y:\n",
    "\n",
    "    if i >= np.median(scotch_y):\n",
    "        y = 1\n",
    "    if i< np.median(scotch_y): \n",
    "        y = 0\n",
    "    scotch_y1.append(y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scotch_y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scotch_x = scotch_data['description'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Powerful, muscular, well-textured, and invigorating. Even within the realm of Ardbeg, this one stands out. The more aggressive notes of coal tar, damp kiln, anise, and smoked seaweed are supported by an array of fruit (black raspberry, black cherry, plum), dark chocolate, espresso, molasses, bacon fat, kalamata olive, and warming cinnamon on the finish. Quite stunning!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scotch_x[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "\n",
    "scotch_x_tokens = []\n",
    "\n",
    "for x in scotch_x:\n",
    "    \n",
    "\n",
    "    tokens = tokenizer.tokenize(x)\n",
    "    scotch_x_tokens.append(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Powerful',\n",
       " ',',\n",
       " 'muscular',\n",
       " ',',\n",
       " 'well-textured',\n",
       " ',',\n",
       " 'and',\n",
       " 'invigorating.',\n",
       " 'Even',\n",
       " 'within',\n",
       " 'the',\n",
       " 'realm',\n",
       " 'of',\n",
       " 'Ardbeg',\n",
       " ',',\n",
       " 'this',\n",
       " 'one',\n",
       " 'stands',\n",
       " 'out.',\n",
       " 'The',\n",
       " 'more',\n",
       " 'aggressive',\n",
       " 'notes',\n",
       " 'of',\n",
       " 'coal',\n",
       " 'tar',\n",
       " ',',\n",
       " 'damp',\n",
       " 'kiln',\n",
       " ',',\n",
       " 'anise',\n",
       " ',',\n",
       " 'and',\n",
       " 'smoked',\n",
       " 'seaweed',\n",
       " 'are',\n",
       " 'supported',\n",
       " 'by',\n",
       " 'an',\n",
       " 'array',\n",
       " 'of',\n",
       " 'fruit',\n",
       " '(',\n",
       " 'black',\n",
       " 'raspberry',\n",
       " ',',\n",
       " 'black',\n",
       " 'cherry',\n",
       " ',',\n",
       " 'plum',\n",
       " ')',\n",
       " ',',\n",
       " 'dark',\n",
       " 'chocolate',\n",
       " ',',\n",
       " 'espresso',\n",
       " ',',\n",
       " 'molasses',\n",
       " ',',\n",
       " 'bacon',\n",
       " 'fat',\n",
       " ',',\n",
       " 'kalamata',\n",
       " 'olive',\n",
       " ',',\n",
       " 'and',\n",
       " 'warming',\n",
       " 'cinnamon',\n",
       " 'on',\n",
       " 'the',\n",
       " 'finish.',\n",
       " 'Quite',\n",
       " 'stunning',\n",
       " '!']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scotch_x_tokens[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scotch_x_canon = []\n",
    "\n",
    "\n",
    "for x in scotch_x_tokens: \n",
    "    canon = utils.canonicalize_words(x)\n",
    "    scotch_x_canon.append(canon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['powerful',\n",
       " ',',\n",
       " 'muscular',\n",
       " ',',\n",
       " 'well-textured',\n",
       " ',',\n",
       " 'and',\n",
       " 'invigorating.',\n",
       " 'even',\n",
       " 'within',\n",
       " 'the',\n",
       " 'realm',\n",
       " 'of',\n",
       " 'ardbeg',\n",
       " ',',\n",
       " 'this',\n",
       " 'one',\n",
       " 'stands',\n",
       " 'out.',\n",
       " 'the',\n",
       " 'more',\n",
       " 'aggressive',\n",
       " 'notes',\n",
       " 'of',\n",
       " 'coal',\n",
       " 'tar',\n",
       " ',',\n",
       " 'damp',\n",
       " 'kiln',\n",
       " ',',\n",
       " 'anise',\n",
       " ',',\n",
       " 'and',\n",
       " 'smoked',\n",
       " 'seaweed',\n",
       " 'are',\n",
       " 'supported',\n",
       " 'by',\n",
       " 'an',\n",
       " 'array',\n",
       " 'of',\n",
       " 'fruit',\n",
       " '(',\n",
       " 'black',\n",
       " 'raspberry',\n",
       " ',',\n",
       " 'black',\n",
       " 'cherry',\n",
       " ',',\n",
       " 'plum',\n",
       " ')',\n",
       " ',',\n",
       " 'dark',\n",
       " 'chocolate',\n",
       " ',',\n",
       " 'espresso',\n",
       " ',',\n",
       " 'molasses',\n",
       " ',',\n",
       " 'bacon',\n",
       " 'fat',\n",
       " ',',\n",
       " 'kalamata',\n",
       " 'olive',\n",
       " ',',\n",
       " 'and',\n",
       " 'warming',\n",
       " 'cinnamon',\n",
       " 'on',\n",
       " 'the',\n",
       " 'finish.',\n",
       " 'quite',\n",
       " 'stunning',\n",
       " '!']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scotch_x_canon[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scotch_flat = []\n",
    "for x in scotch_x_canon:\n",
    "    for i in x:\n",
    "        scotch_flat.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['magnificently',\n",
       " 'powerful',\n",
       " 'and',\n",
       " 'intense.',\n",
       " 'caramels',\n",
       " ',',\n",
       " 'dried',\n",
       " 'peats',\n",
       " ',',\n",
       " 'elegant',\n",
       " 'cigar',\n",
       " 'smoke',\n",
       " ',',\n",
       " 'seeds',\n",
       " 'scraped',\n",
       " 'from',\n",
       " 'vanilla',\n",
       " 'beans',\n",
       " ',',\n",
       " 'brand',\n",
       " 'new',\n",
       " 'pencils',\n",
       " ',',\n",
       " 'peppercorn',\n",
       " ',',\n",
       " 'coriander',\n",
       " 'seeds',\n",
       " ',',\n",
       " 'and',\n",
       " 'star',\n",
       " 'anise',\n",
       " 'make',\n",
       " 'for',\n",
       " 'a',\n",
       " 'deeply',\n",
       " 'satisfying',\n",
       " 'nosing',\n",
       " 'experience.',\n",
       " 'silky',\n",
       " 'caramels',\n",
       " ',',\n",
       " 'bountiful',\n",
       " 'fruits',\n",
       " 'of',\n",
       " 'ripe',\n",
       " 'peach',\n",
       " ',',\n",
       " 'stewed',\n",
       " 'apple',\n",
       " ',',\n",
       " 'orange',\n",
       " 'pith',\n",
       " ',',\n",
       " 'and',\n",
       " 'pervasive',\n",
       " 'smoke',\n",
       " 'with',\n",
       " 'elements',\n",
       " 'of',\n",
       " 'burnt',\n",
       " 'tobacco.',\n",
       " 'an',\n",
       " 'abiding',\n",
       " 'finish',\n",
       " 'of',\n",
       " 'smoke',\n",
       " ',',\n",
       " 'dry',\n",
       " 'spices',\n",
       " ',',\n",
       " 'and',\n",
       " 'banoffee',\n",
       " 'pie',\n",
       " 'sweetness.',\n",
       " 'close',\n",
       " 'to',\n",
       " 'perfection.',\n",
       " 'editor',\n",
       " \"'s\",\n",
       " 'choice',\n",
       " 'what',\n",
       " 'impresses',\n",
       " 'me',\n",
       " 'most',\n",
       " 'is',\n",
       " 'how',\n",
       " 'this',\n",
       " 'whisky',\n",
       " 'evolves',\n",
       " ';',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'incredibly',\n",
       " 'complex.',\n",
       " 'on',\n",
       " 'the',\n",
       " 'nose',\n",
       " 'and',\n",
       " 'palate',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'thick',\n",
       " ',',\n",
       " 'viscous',\n",
       " ',',\n",
       " 'whisky',\n",
       " 'with',\n",
       " 'notes',\n",
       " 'of',\n",
       " 'sticky',\n",
       " 'toffee',\n",
       " ',',\n",
       " 'earthy',\n",
       " 'oak',\n",
       " ',',\n",
       " 'fig',\n",
       " 'cake',\n",
       " ',',\n",
       " 'roasted',\n",
       " 'nuts',\n",
       " ',',\n",
       " 'fallen',\n",
       " 'fruit',\n",
       " ',',\n",
       " 'pancake',\n",
       " 'batter',\n",
       " ',',\n",
       " 'black',\n",
       " 'cherry',\n",
       " ',',\n",
       " 'ripe',\n",
       " 'peach',\n",
       " ',',\n",
       " 'dark',\n",
       " 'chocolate-covered',\n",
       " 'espresso',\n",
       " 'bean',\n",
       " ',',\n",
       " 'polished',\n",
       " 'leather',\n",
       " ',',\n",
       " 'tobacco',\n",
       " ',',\n",
       " 'a',\n",
       " 'hint',\n",
       " 'of',\n",
       " 'wild',\n",
       " 'game',\n",
       " ',',\n",
       " 'and',\n",
       " 'lingering',\n",
       " ',',\n",
       " 'leafy',\n",
       " 'damp',\n",
       " 'kiln',\n",
       " 'smoke.',\n",
       " 'flavors',\n",
       " 'continue',\n",
       " 'on',\n",
       " 'the',\n",
       " 'palate',\n",
       " 'long',\n",
       " 'after',\n",
       " 'swallowing.',\n",
       " 'this',\n",
       " 'is',\n",
       " 'what',\n",
       " 'we',\n",
       " 'all',\n",
       " 'hope',\n",
       " 'for',\n",
       " '(',\n",
       " 'and',\n",
       " 'dream',\n",
       " 'of',\n",
       " ')',\n",
       " 'in',\n",
       " 'an',\n",
       " 'older',\n",
       " 'whisky',\n",
       " '!',\n",
       " 'there',\n",
       " 'have',\n",
       " 'been',\n",
       " 'some',\n",
       " 'legendary',\n",
       " 'bowmores',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mid-60s',\n",
       " 'and',\n",
       " 'this',\n",
       " 'is',\n",
       " 'every',\n",
       " 'bit',\n",
       " 'their',\n",
       " 'equal.',\n",
       " 'all',\n",
       " 'of',\n",
       " 'them',\n",
       " 'share',\n",
       " 'a',\n",
       " 'remarkable',\n",
       " 'aroma',\n",
       " 'of',\n",
       " 'tropical',\n",
       " 'fruit',\n",
       " ',',\n",
       " 'which',\n",
       " 'here',\n",
       " 'moves',\n",
       " 'into',\n",
       " 'hallucinatory',\n",
       " 'intensity',\n",
       " ':',\n",
       " 'guava',\n",
       " ',',\n",
       " 'mango',\n",
       " ',',\n",
       " 'peach',\n",
       " ',',\n",
       " 'pineapple',\n",
       " ',',\n",
       " 'grapefruit.',\n",
       " 'there',\n",
       " '’',\n",
       " 's',\n",
       " 'a',\n",
       " 'very',\n",
       " 'light',\n",
       " 'touch',\n",
       " 'of',\n",
       " 'peat',\n",
       " 'smoke',\n",
       " ',',\n",
       " 'more',\n",
       " 'a',\n",
       " 'memory',\n",
       " 'of',\n",
       " 'islay',\n",
       " 'than',\n",
       " 'the',\n",
       " 'reality.',\n",
       " 'concentrated',\n",
       " ';',\n",
       " 'even',\n",
       " 'at',\n",
       " 'low',\n",
       " 'strength',\n",
       " 'the',\n",
       " 'palate',\n",
       " 'is',\n",
       " 'silky',\n",
       " ',',\n",
       " 'heady',\n",
       " ',',\n",
       " 'and',\n",
       " 'haunting',\n",
       " ',',\n",
       " 'and',\n",
       " 'lasts',\n",
       " 'forever',\n",
       " 'in',\n",
       " 'the',\n",
       " 'dry',\n",
       " 'glass.',\n",
       " 'a',\n",
       " 'legend',\n",
       " 'is',\n",
       " 'born.',\n",
       " '(',\n",
       " 'eight',\n",
       " 'bottles',\n",
       " 'only',\n",
       " 'for',\n",
       " 'the',\n",
       " 'u.s.',\n",
       " ')',\n",
       " 'editor',\n",
       " \"'s\",\n",
       " 'choice',\n",
       " '.',\n",
       " 'with',\n",
       " 'a',\n",
       " 'name',\n",
       " 'inspired',\n",
       " 'by',\n",
       " 'a',\n",
       " 'DGDGDGDG',\n",
       " 'buster',\n",
       " 'keaton',\n",
       " 'movie',\n",
       " ',',\n",
       " 'only',\n",
       " 'DGDGDGDG',\n",
       " 'bottles',\n",
       " 'produced',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'news',\n",
       " 'that',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'two',\n",
       " 'batches',\n",
       " 'is',\n",
       " 'more',\n",
       " 'than',\n",
       " 'DGDG',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'the',\n",
       " 'clues',\n",
       " 'were',\n",
       " 'there',\n",
       " 'that',\n",
       " 'this',\n",
       " 'blend',\n",
       " 'was',\n",
       " 'never',\n",
       " 'going',\n",
       " 'to',\n",
       " 'be',\n",
       " 'cheap.',\n",
       " 'it',\n",
       " 'is',\n",
       " \"n't\",\n",
       " ',',\n",
       " 'but',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'superb',\n",
       " ',',\n",
       " 'rich',\n",
       " 'in',\n",
       " 'flavor',\n",
       " 'that',\n",
       " 'screams',\n",
       " 'dusty',\n",
       " 'old',\n",
       " 'oak',\n",
       " 'office',\n",
       " ',',\n",
       " 'fresh',\n",
       " 'polish',\n",
       " ',',\n",
       " 'and',\n",
       " 'sunday',\n",
       " 'church',\n",
       " ',',\n",
       " 'with',\n",
       " 'spices',\n",
       " ',',\n",
       " 'oak',\n",
       " 'dried',\n",
       " 'fruits',\n",
       " ',',\n",
       " 'squiggly',\n",
       " 'raisins',\n",
       " ',',\n",
       " 'and',\n",
       " 'a',\n",
       " 'surprising',\n",
       " 'melting',\n",
       " 'fruit-and-nut',\n",
       " 'dairy',\n",
       " 'chocolate',\n",
       " 'back',\n",
       " 'story',\n",
       " '.',\n",
       " 'captivating',\n",
       " ',',\n",
       " 'enticing',\n",
       " ',',\n",
       " 'and',\n",
       " 'wonderfully',\n",
       " 'charming',\n",
       " ',',\n",
       " 'this',\n",
       " 'first',\n",
       " 'blended',\n",
       " 'malt',\n",
       " 'from',\n",
       " 'chivas',\n",
       " 'regal',\n",
       " 'contains',\n",
       " 'selections',\n",
       " 'of',\n",
       " 'five',\n",
       " 'speyside',\n",
       " 'malts',\n",
       " ':',\n",
       " 'strathisla',\n",
       " ',',\n",
       " 'longmorn',\n",
       " ',',\n",
       " 'tormore',\n",
       " ',',\n",
       " 'allt-a-bhainne',\n",
       " ',',\n",
       " 'and',\n",
       " 'braeval.',\n",
       " 'red',\n",
       " 'apple',\n",
       " ',',\n",
       " 'cherry',\n",
       " ',',\n",
       " 'raspberry',\n",
       " 'fudge',\n",
       " ',',\n",
       " 'peach',\n",
       " 'and',\n",
       " 'mango',\n",
       " 'fruit',\n",
       " 'salad',\n",
       " ',',\n",
       " 'dusting',\n",
       " 'of',\n",
       " 'cinnamon',\n",
       " ',',\n",
       " 'and',\n",
       " 'dry',\n",
       " 'heather',\n",
       " 'sprigs.',\n",
       " 'in',\n",
       " 'essence',\n",
       " ',',\n",
       " 'it',\n",
       " '’',\n",
       " 's',\n",
       " 'rich',\n",
       " 'and',\n",
       " 'satisfying',\n",
       " ',',\n",
       " 'with',\n",
       " 'dark',\n",
       " 'vanilla',\n",
       " ',',\n",
       " 'apricot',\n",
       " ',',\n",
       " 'bourneville-covered',\n",
       " 'brazil',\n",
       " 'nuts',\n",
       " ',',\n",
       " 'and',\n",
       " 'tangerine',\n",
       " ',',\n",
       " 'smoothed',\n",
       " 'over',\n",
       " 'by',\n",
       " 'caramel',\n",
       " 'and',\n",
       " 'wood',\n",
       " 'spices',\n",
       " ',',\n",
       " 'maltiness',\n",
       " ',',\n",
       " 'and',\n",
       " 'gingersnap',\n",
       " 'biscuits.',\n",
       " 'quite',\n",
       " 'heavenly.',\n",
       " 'editor',\n",
       " \"'s\",\n",
       " 'choice',\n",
       " 'powerful',\n",
       " ',',\n",
       " 'muscular',\n",
       " ',',\n",
       " 'well-textured',\n",
       " ',',\n",
       " 'and',\n",
       " 'invigorating.',\n",
       " 'even',\n",
       " 'within',\n",
       " 'the',\n",
       " 'realm',\n",
       " 'of',\n",
       " 'ardbeg',\n",
       " ',',\n",
       " 'this',\n",
       " 'one',\n",
       " 'stands',\n",
       " 'out.',\n",
       " 'the',\n",
       " 'more',\n",
       " 'aggressive',\n",
       " 'notes',\n",
       " 'of',\n",
       " 'coal',\n",
       " 'tar',\n",
       " ',',\n",
       " 'damp',\n",
       " 'kiln',\n",
       " ',',\n",
       " 'anise',\n",
       " ',',\n",
       " 'and',\n",
       " 'smoked',\n",
       " 'seaweed',\n",
       " 'are',\n",
       " 'supported',\n",
       " 'by',\n",
       " 'an',\n",
       " 'array',\n",
       " 'of',\n",
       " 'fruit',\n",
       " '(',\n",
       " 'black',\n",
       " 'raspberry',\n",
       " ',',\n",
       " 'black',\n",
       " 'cherry',\n",
       " ',',\n",
       " 'plum',\n",
       " ')',\n",
       " ',',\n",
       " 'dark',\n",
       " 'chocolate',\n",
       " ',',\n",
       " 'espresso',\n",
       " ',',\n",
       " 'molasses',\n",
       " ',',\n",
       " 'bacon',\n",
       " 'fat',\n",
       " ',',\n",
       " 'kalamata',\n",
       " 'olive',\n",
       " ',',\n",
       " 'and',\n",
       " 'warming',\n",
       " 'cinnamon',\n",
       " 'on',\n",
       " 'the',\n",
       " 'finish.',\n",
       " 'quite',\n",
       " 'stunning',\n",
       " '!',\n",
       " 'deep',\n",
       " 'gold',\n",
       " 'color.',\n",
       " 'surprisingly',\n",
       " 'lively',\n",
       " 'on',\n",
       " 'the',\n",
       " 'nose',\n",
       " 'for',\n",
       " 'its',\n",
       " 'age.',\n",
       " 'a',\n",
       " 'complex',\n",
       " 'array',\n",
       " 'of',\n",
       " 'fruit',\n",
       " '(',\n",
       " 'tangerine',\n",
       " ',',\n",
       " 'sultana',\n",
       " ',',\n",
       " 'pink',\n",
       " 'grapefruit',\n",
       " ',',\n",
       " 'papaya',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'general',\n",
       " 'overall',\n",
       " 'citrus',\n",
       " 'dna',\n",
       " 'that',\n",
       " 'you',\n",
       " '’',\n",
       " 'll',\n",
       " 'find',\n",
       " 'in',\n",
       " 'old',\n",
       " 'bowmores',\n",
       " ')',\n",
       " ',',\n",
       " 'with',\n",
       " 'balancing',\n",
       " 'notes',\n",
       " 'of',\n",
       " 'honey',\n",
       " 'and',\n",
       " 'vanilla.',\n",
       " 'a',\n",
       " 'hint',\n",
       " 'of',\n",
       " 'damp',\n",
       " 'smoke',\n",
       " 'and',\n",
       " 'coconut.',\n",
       " 'just',\n",
       " 'like',\n",
       " 'with',\n",
       " 'black',\n",
       " 'bowmore',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'texturally',\n",
       " 'soothing',\n",
       " 'whisky',\n",
       " 'on',\n",
       " 'the',\n",
       " 'palate',\n",
       " ',',\n",
       " 'which',\n",
       " 'continues',\n",
       " 'to',\n",
       " 'evolve',\n",
       " 'in',\n",
       " 'waves',\n",
       " '--',\n",
       " 'first',\n",
       " 'the',\n",
       " 'sweet',\n",
       " 'honey',\n",
       " ',',\n",
       " 'coating',\n",
       " 'vanilla',\n",
       " ',',\n",
       " 'and',\n",
       " 'lively',\n",
       " 'fruit',\n",
       " ',',\n",
       " 'then',\n",
       " 'turning',\n",
       " 'quite',\n",
       " 'visceral',\n",
       " ',',\n",
       " 'with',\n",
       " 'juicy',\n",
       " 'oak',\n",
       " ',',\n",
       " 'damp',\n",
       " 'earth',\n",
       " ',',\n",
       " 'deep',\n",
       " 'peat',\n",
       " 'smoke',\n",
       " ',',\n",
       " 'and',\n",
       " 'charcoal',\n",
       " ',',\n",
       " 'followed',\n",
       " 'by',\n",
       " 'another',\n",
       " 'wave',\n",
       " 'of',\n",
       " 'fruit',\n",
       " '(',\n",
       " 'this',\n",
       " 'time',\n",
       " ',',\n",
       " 'dried',\n",
       " 'fruit',\n",
       " ')',\n",
       " ',',\n",
       " 'finishing',\n",
       " 'off',\n",
       " 'with',\n",
       " 'subtle',\n",
       " 'charred',\n",
       " 'oak',\n",
       " 'and',\n",
       " 'roasted',\n",
       " 'nuts.',\n",
       " 'this',\n",
       " 'whisky',\n",
       " 'is',\n",
       " 'better',\n",
       " 'than',\n",
       " 'white',\n",
       " 'bowmore',\n",
       " ',',\n",
       " 'and',\n",
       " 'it',\n",
       " 'falls',\n",
       " 'just',\n",
       " 'short',\n",
       " 'of',\n",
       " 'black',\n",
       " 'bowmore',\n",
       " '(',\n",
       " 'which',\n",
       " 'i',\n",
       " 'rated',\n",
       " 'DGDG',\n",
       " ')',\n",
       " ',',\n",
       " 'because',\n",
       " 'it',\n",
       " '’',\n",
       " 's',\n",
       " 'just',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'softer',\n",
       " 'and',\n",
       " 'less',\n",
       " 'vibrant',\n",
       " 'on',\n",
       " 'the',\n",
       " 'palate',\n",
       " '.',\n",
       " 'definitely',\n",
       " 'showing',\n",
       " 'its',\n",
       " 'age',\n",
       " ',',\n",
       " 'but',\n",
       " 'not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'way',\n",
       " '—',\n",
       " 'the',\n",
       " 'distillery',\n",
       " 'character',\n",
       " 'is',\n",
       " 'still',\n",
       " 'there.',\n",
       " 'solid',\n",
       " 'foundation',\n",
       " 'of',\n",
       " 'thick',\n",
       " ',',\n",
       " 'chewy',\n",
       " 'toffee',\n",
       " ',',\n",
       " 'old',\n",
       " 'pot',\n",
       " 'still',\n",
       " 'rum',\n",
       " ',',\n",
       " 'and',\n",
       " 'fig',\n",
       " 'cake.',\n",
       " 'fruity',\n",
       " 'too',\n",
       " ',',\n",
       " 'with',\n",
       " 'notes',\n",
       " 'of',\n",
       " 'golden',\n",
       " 'raisin',\n",
       " 'and',\n",
       " 'nectarine.',\n",
       " 'soft',\n",
       " ',',\n",
       " 'seductive',\n",
       " 'peat',\n",
       " 'smoke',\n",
       " ',',\n",
       " 'juicy',\n",
       " 'oak',\n",
       " ',',\n",
       " 'cinnamon',\n",
       " ',',\n",
       " 'and',\n",
       " 'brine',\n",
       " 'round',\n",
       " 'out',\n",
       " 'the',\n",
       " 'palate.',\n",
       " 'excellent',\n",
       " 'balance',\n",
       " '!',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'finest',\n",
       " 'bowmore',\n",
       " 'whiskies',\n",
       " 'i',\n",
       " '’',\n",
       " 've',\n",
       " 'ever',\n",
       " 'tasted',\n",
       " '(',\n",
       " 'and',\n",
       " ',',\n",
       " 'at',\n",
       " 'this',\n",
       " 'price',\n",
       " ',',\n",
       " 'will',\n",
       " 'probably',\n",
       " 'never',\n",
       " 'taste',\n",
       " 'again.',\n",
       " ')',\n",
       " '(',\n",
       " 'editor',\n",
       " \"'s\",\n",
       " 'pick',\n",
       " ')',\n",
       " 'the',\n",
       " 'dalmore',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'a',\n",
       " 'handful',\n",
       " 'of',\n",
       " 'whiskies',\n",
       " 'that',\n",
       " 'seem',\n",
       " 'to',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'age',\n",
       " 'in',\n",
       " 'the',\n",
       " 'cask',\n",
       " 'for',\n",
       " 'many',\n",
       " 'decades',\n",
       " 'and',\n",
       " 'still',\n",
       " 'improve.',\n",
       " 'this',\n",
       " 'one',\n",
       " 'is',\n",
       " 'incredibly',\n",
       " 'viscous',\n",
       " 'on',\n",
       " 'the',\n",
       " 'nose',\n",
       " 'and',\n",
       " 'palate',\n",
       " '(',\n",
       " 'and',\n",
       " 'very',\n",
       " 'heavy',\n",
       " 'on',\n",
       " 'the',\n",
       " 'tongue',\n",
       " ')',\n",
       " ',',\n",
       " 'with',\n",
       " 'chewy',\n",
       " 'toffee',\n",
       " 'and',\n",
       " 'old',\n",
       " 'pot',\n",
       " 'still',\n",
       " 'rum.',\n",
       " 'the',\n",
       " 'classic',\n",
       " 'dalmore',\n",
       " 'marmalade',\n",
       " 'note',\n",
       " 'shines',\n",
       " 'throughout',\n",
       " ',',\n",
       " 'along',\n",
       " 'with',\n",
       " 'vanilla',\n",
       " 'cream',\n",
       " ',',\n",
       " 'an',\n",
       " 'array',\n",
       " 'of',\n",
       " 'dried',\n",
       " 'spices',\n",
       " '(',\n",
       " 'especially',\n",
       " 'cinnamon',\n",
       " 'and',\n",
       " 'evergreen',\n",
       " ')',\n",
       " ',',\n",
       " 'juicy',\n",
       " 'oak',\n",
       " ',',\n",
       " 'forest',\n",
       " 'bedding',\n",
       " ',',\n",
       " 'rancio',\n",
       " ',',\n",
       " 'old',\n",
       " 'armagnac',\n",
       " ',',\n",
       " 'polished',\n",
       " 'leather',\n",
       " ',',\n",
       " 'tobacco',\n",
       " ',',\n",
       " 'maple',\n",
       " 'syrup',\n",
       " ',',\n",
       " 'dark',\n",
       " 'chocolate',\n",
       " ',',\n",
       " 'almond',\n",
       " 'macaroon',\n",
       " ',',\n",
       " 'and',\n",
       " 'subtle',\n",
       " 'espresso.',\n",
       " 'long',\n",
       " ',',\n",
       " 'mouth-coating',\n",
       " 'finish.',\n",
       " 'the',\n",
       " 'flavors',\n",
       " 'evolve',\n",
       " 'like',\n",
       " 'waves',\n",
       " 'lapping',\n",
       " 'on',\n",
       " 'the',\n",
       " 'palate',\n",
       " '--',\n",
       " 'especially',\n",
       " 'the',\n",
       " 'interplay',\n",
       " 'with',\n",
       " 'the',\n",
       " 'oak.',\n",
       " 'i',\n",
       " 'can',\n",
       " '’',\n",
       " 't',\n",
       " 'drink',\n",
       " 'this',\n",
       " 'whisky',\n",
       " 'slowly',\n",
       " 'enough.',\n",
       " 'a',\n",
       " 'rare',\n",
       " 'experience',\n",
       " 'for',\n",
       " 'the',\n",
       " 'lucky',\n",
       " 'few',\n",
       " 'who',\n",
       " 'can',\n",
       " 'afford',\n",
       " 'it.',\n",
       " '(',\n",
       " 'price',\n",
       " 'is',\n",
       " 'per',\n",
       " '100ml',\n",
       " ')',\n",
       " '.',\n",
       " 'a',\n",
       " 'rich',\n",
       " 'amber',\n",
       " 'color',\n",
       " 'and',\n",
       " 'elegantly',\n",
       " 'oxidized',\n",
       " 'notes',\n",
       " 'greet',\n",
       " 'you.',\n",
       " 'there',\n",
       " 'are',\n",
       " 'luscious',\n",
       " 'old',\n",
       " 'fruits—pineapple',\n",
       " ',',\n",
       " 'dried',\n",
       " 'peach',\n",
       " ',',\n",
       " 'apricot—and',\n",
       " 'puffs',\n",
       " 'of',\n",
       " 'coal-like',\n",
       " 'smokiness.',\n",
       " 'in',\n",
       " 'time',\n",
       " ',',\n",
       " 'sweet',\n",
       " 'spices',\n",
       " '(',\n",
       " 'cumin',\n",
       " 'especially',\n",
       " ')',\n",
       " 'emerge.',\n",
       " 'superbly',\n",
       " 'balanced.',\n",
       " 'the',\n",
       " 'palate',\n",
       " ',',\n",
       " 'while',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scotch_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 11,520\n"
     ]
    }
   ],
   "source": [
    "vocab = vocabulary.Vocabulary(scotch_flat, size=None)  # size=None means unlimited\n",
    "print(\"Vocabulary size: {:,}\".format(vocab.size))\n",
    "\n",
    "\n",
    "scotch_x_ids = []\n",
    "for x in scotch_x_canon:\n",
    "    x_ids = vocab.words_to_ids(x)\n",
    "    scotch_x_ids.append(x_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11520"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = vocab.size\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[612,\n",
       " 3,\n",
       " 1981,\n",
       " 3,\n",
       " 4130,\n",
       " 3,\n",
       " 4,\n",
       " 2833,\n",
       " 191,\n",
       " 1800,\n",
       " 5,\n",
       " 2834,\n",
       " 7,\n",
       " 554,\n",
       " 3,\n",
       " 11,\n",
       " 72,\n",
       " 3353,\n",
       " 1226,\n",
       " 5,\n",
       " 32,\n",
       " 1227,\n",
       " 22,\n",
       " 7,\n",
       " 555,\n",
       " 363,\n",
       " 3,\n",
       " 252,\n",
       " 802,\n",
       " 3,\n",
       " 406,\n",
       " 3,\n",
       " 4,\n",
       " 325,\n",
       " 246,\n",
       " 50,\n",
       " 4131,\n",
       " 59,\n",
       " 37,\n",
       " 988,\n",
       " 7,\n",
       " 30,\n",
       " 17,\n",
       " 96,\n",
       " 350,\n",
       " 3,\n",
       " 96,\n",
       " 292,\n",
       " 3,\n",
       " 339,\n",
       " 18,\n",
       " 3,\n",
       " 89,\n",
       " 47,\n",
       " 3,\n",
       " 894,\n",
       " 3,\n",
       " 584,\n",
       " 3,\n",
       " 1463,\n",
       " 949,\n",
       " 3,\n",
       " 2173,\n",
       " 614,\n",
       " 3,\n",
       " 4,\n",
       " 420,\n",
       " 107,\n",
       " 13,\n",
       " 5,\n",
       " 48,\n",
       " 85,\n",
       " 1531,\n",
       " 154]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scotch_x_ids[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 300\n",
    "scotch_x_pad = []\n",
    "scotch_ns = []\n",
    "for i in scotch_x_ids:\n",
    "    \n",
    "    pad_len = max_len - len(i)\n",
    "    pad_i = np.pad(i, (0, pad_len), 'constant', constant_values =0)\n",
    "    scotch_ns.append(len(i))\n",
    "    scotch_x_pad.append(pad_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 612,    3, 1981,    3, 4130,    3,    4, 2833,  191, 1800,    5,\n",
       "       2834,    7,  554,    3,   11,   72, 3353, 1226,    5,   32, 1227,\n",
       "         22,    7,  555,  363,    3,  252,  802,    3,  406,    3,    4,\n",
       "        325,  246,   50, 4131,   59,   37,  988,    7,   30,   17,   96,\n",
       "        350,    3,   96,  292,    3,  339,   18,    3,   89,   47,    3,\n",
       "        894,    3,  584,    3, 1463,  949,    3, 2173,  614,    3,    4,\n",
       "        420,  107,   13,    5,   48,   85, 1531,  154,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scotch_x_pad[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scotch_x_pad_np = np.asarray(scotch_x_pad)\n",
    "scotch_y_np = np.asarray(scotch_y)\n",
    "# scotch_y_np = scotch_y_np.dtype(np.float32)\n",
    "scotch_ns_np = np.asarray(scotch_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = scotch_x_pad_np[0:1790]\n",
    "train_ns = scotch_ns_np[0:1790]\n",
    "train_y = scotch_y_np[0:1790]\n",
    "\n",
    "test_x = scotch_x_pad_np[1791:2100]\n",
    "test_ns = scotch_ns_np[1791:2100]\n",
    "test_y = scotch_y_np[1791:2100]\n",
    "\n",
    "dev_x = scotch_x_pad_np[2101::]\n",
    "dev_ns = scotch_ns_np[2101::]\n",
    "dev_y = scotch_y_np[2101::]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SST from data/sst/trainDevTestTrees_PTB.zip\n",
      "Training set:     8,544 trees\n",
      "Development set:  1,101 trees\n",
      "Test set:         2,210 trees\n",
      "Building vocabulary - 16,474 words\n",
      "Processing to phrases...  Done!\n",
      "Splits: train / dev / test : 98,794 / 13,142 / 26,052\n"
     ]
    }
   ],
   "source": [
    "import sst\n",
    "ds = sst.SSTDataset(V=20000).process(label_scheme=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  85.,   90.,  113.,  690.,  110.,  120.,   55.,  170.,  170.,\n",
       "        180.,   60.,   50.,   85.,   88.,  117.,  138.,   84.,   85.,\n",
       "        150.,   45.,  265.,  135.,  140.,  155.,  160.,  100.,   73.,\n",
       "        160.,  210.,  592.,  125.,   36.,   90.,  155.,  900.,   50.,\n",
       "        100.,  156.,  700.,   89.,   67.,   73.,  440.,   51.,   90.,\n",
       "         93.,  111.,  130.,   45.,   49.,  220.,   80.,  137.,   76.,\n",
       "         75.,   65.,  121.,  190.,   70.,   44.,   90., 2750.,   70.,\n",
       "         56.,  567.,  185.,   63.,   97.,   70.,   40.,   40.,   73.,\n",
       "         55.,  180.,   70.,   65.,   30.,   70.,  119.,  154.,  164.,\n",
       "        104.,  190.,   54.,  125.,   60.,  108.,   78.,   40.,  325.,\n",
       "        100.,   90.,   45.,   61.,   61.,   46.,  119.,  160.,  100.,\n",
       "        142.,   77.,   32.,   98.,   60.,  168.,  119.,   73.,   69.,\n",
       "        110.,   90.,   90.,   95.,   72.,   73.,   76.,   37.,   33.,\n",
       "         44.,   53.,   65.,  348.,   61.,  115.,  126.,   60.,  195.,\n",
       "         69.,   22.,   40.,   55.,  700.,  212.,   90.,  101.,   75.,\n",
       "         50.,  150.,   88.,  465.,   65.,   75.,   60., 1250.,  135.,\n",
       "        100.,   72.,   55.,   32.,  180.,   90.,   65.,  125.,   65.,\n",
       "         56.,  288.,   55.,   72.,   84.,   44.,   90.,  150.,   65.,\n",
       "         60.,  151.,   73.,   73.,   70.,  115.,  100.,   59.,   52.,\n",
       "         48.,   59.,  100.,   65.,  120.,  124.,   53.,   65.,  200.,\n",
       "         80.,  100.,  100.,   30.,  200.,  100.,   42.,   50.,   70.,\n",
       "         65.,   70.,   70.,   40.,   40.,   55.,   30.,   55.,   58.,\n",
       "         52.,  157.,   91.,   64.,   18.,   15.,   67.,  130.,   56.,\n",
       "        101.,   88.,  191.,  100.,  206.,   35.,   73.,  135.,   50.,\n",
       "         25.,   17.,  145.,   40.,  126.,  185.,  200.,   45.,   33.,\n",
       "        145.,   35.,   80.,  160.,  153.,  140.,   65.,   65.,  135.,\n",
       "         84.,  109.,  210.,   93.,  115.,  175.,   45.,   60.,  899.,\n",
       "        109.,   60.,  238.,   63.,   55.,   80.,   70.,  138.,   80.,\n",
       "         75.,   25.,  133.,   90.,  125.,  170.,  135.,  300.,  155.,\n",
       "         67.,   75.,   52.,   40.,  112.,   53.,   78.,   82.,   61.,\n",
       "         60.,  239.,   80.,   21.,  134.,  340.,   14.,   12.,   53.,\n",
       "         75.,  155.,  146.,  108.,   56.,  117.,   82.,   98.,  109.,\n",
       "        120.,   95.,   50.,   70.,   40.,   70.,   30.,  130.,  576.,\n",
       "       1800.,   63.,   82.,   93.,  102.,   80.,   85.,   94.,  160.,\n",
       "        123.,   57.,   81.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model (Naive Bayes) Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65%\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(train_x, train_y)\n",
    "y_pred = nb.predict(test_x)\n",
    "\n",
    "acc = accuracy_score(test_y, y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.02f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.900e+01, 1.070e+02, 3.200e+01, 9.500e+01, 3.000e+01, 1.080e+02,\n",
       "       7.800e+01, 7.800e+01, 2.250e+02, 6.700e+01, 3.000e+04, 1.510e+02,\n",
       "       1.510e+02, 2.500e+02, 1.100e+03, 7.000e+01, 3.500e+03, 1.100e+02,\n",
       "       9.900e+01, 2.500e+02, 4.060e+02, 8.000e+01, 4.000e+02, 2.000e+02,\n",
       "       5.000e+01, 1.190e+02, 1.510e+02, 4.150e+02, 2.000e+02, 8.500e+01,\n",
       "       1.170e+02, 1.140e+02, 5.000e+01, 6.700e+01, 4.220e+02, 1.080e+02,\n",
       "       5.000e+01, 1.500e+03, 4.500e+03, 8.000e+01, 9.500e+01, 9.900e+01,\n",
       "       9.900e+01, 2.400e+02, 1.010e+02, 2.250e+02, 1.900e+03, 1.450e+02,\n",
       "       2.500e+01, 8.000e+01, 2.940e+02, 1.250e+02, 6.300e+01, 9.700e+01,\n",
       "       6.000e+02, 7.800e+01, 1.150e+02, 9.900e+01, 1.230e+02, 1.510e+02,\n",
       "       1.380e+02, 8.000e+01, 7.200e+01, 1.150e+02, 3.000e+02, 4.500e+01,\n",
       "       7.500e+01, 3.000e+01, 8.200e+01, 5.120e+02, 1.230e+02, 9.600e+01,\n",
       "       2.500e+02, 6.300e+01, 9.900e+01, 8.900e+01, 4.800e+01, 1.030e+02,\n",
       "       4.800e+01, 3.000e+02, 1.150e+02, 6.700e+01, 1.080e+02, 5.000e+01,\n",
       "       7.600e+01, 1.400e+02, 6.370e+02, 6.900e+01, 4.000e+02, 2.500e+02,\n",
       "       7.500e+01, 6.370e+02, 5.300e+01, 7.800e+01, 4.000e+02, 2.500e+02,\n",
       "       3.220e+02, 1.100e+03, 7.000e+01, 1.170e+02, 7.800e+01, 5.800e+01,\n",
       "       1.600e+02, 7.600e+01, 1.520e+02, 1.050e+02, 4.000e+03, 1.080e+02,\n",
       "       5.500e+01, 3.000e+01, 8.000e+01, 1.180e+02, 3.000e+01, 9.800e+01,\n",
       "       1.170e+02, 5.000e+01, 3.000e+01, 8.000e+01, 7.500e+03, 8.000e+01,\n",
       "       9.200e+01, 5.400e+01, 6.900e+01, 5.400e+01, 2.700e+02, 1.690e+02,\n",
       "       6.600e+01, 1.110e+02, 1.100e+02, 4.300e+01, 7.500e+01, 7.400e+01,\n",
       "       9.200e+01, 5.500e+01, 8.900e+01, 3.500e+01, 9.900e+01, 5.700e+01,\n",
       "       8.500e+01, 1.270e+02, 6.000e+02, 6.000e+01, 7.100e+01, 1.810e+02,\n",
       "       7.000e+01, 4.000e+01, 6.900e+01, 6.500e+01, 6.250e+02, 1.300e+02,\n",
       "       1.500e+02, 1.500e+03, 7.400e+01, 1.250e+02, 1.600e+02, 4.500e+01,\n",
       "       9.700e+01, 4.000e+03, 1.600e+02, 5.550e+02, 1.150e+02, 4.220e+02,\n",
       "       2.460e+02, 1.800e+02, 1.270e+02, 2.500e+02, 4.000e+02, 8.900e+01,\n",
       "       1.230e+02, 4.000e+01, 1.080e+02, 1.100e+03, 2.750e+02, 7.100e+01,\n",
       "       7.800e+01, 5.800e+01, 6.500e+01, 1.000e+02, 5.800e+01, 1.590e+02,\n",
       "       2.250e+02, 6.700e+01, 5.000e+01, 1.350e+02, 5.800e+01, 1.100e+02,\n",
       "       1.510e+02, 6.300e+01, 6.300e+01, 6.000e+02, 6.900e+01, 1.600e+02,\n",
       "       6.150e+02, 2.500e+02, 1.700e+02, 9.500e+01, 7.500e+01, 4.500e+01,\n",
       "       1.800e+02, 7.800e+01, 1.600e+02, 5.000e+01, 1.150e+02, 4.000e+02,\n",
       "       1.100e+02, 8.100e+01, 5.300e+01, 2.600e+02, 8.300e+01, 3.000e+02,\n",
       "       1.400e+02, 1.600e+02, 8.000e+01, 4.000e+01, 7.800e+01, 1.110e+02,\n",
       "       4.000e+03, 7.400e+01, 1.100e+02, 7.800e+01, 4.500e+01, 1.500e+03,\n",
       "       6.200e+01, 1.800e+02, 5.800e+01, 1.100e+03, 6.500e+01, 3.500e+01,\n",
       "       2.000e+02, 1.650e+02, 1.100e+02, 4.000e+01, 5.120e+02, 1.141e+03,\n",
       "       1.600e+02, 1.270e+02, 1.450e+02, 1.100e+02, 5.300e+01, 2.250e+02,\n",
       "       1.510e+02, 3.920e+02, 1.500e+02, 1.190e+02, 1.450e+02, 4.200e+01,\n",
       "       2.000e+04, 1.370e+02, 1.100e+03, 4.400e+01, 1.270e+02, 1.100e+02,\n",
       "       8.000e+01, 1.260e+02, 6.000e+01, 2.450e+02, 3.000e+02, 7.800e+01,\n",
       "       2.339e+03, 5.500e+01, 1.110e+02, 4.000e+03, 9.500e+01, 4.000e+01,\n",
       "       1.050e+02, 1.800e+02, 7.400e+01, 9.500e+01, 8.200e+01, 5.900e+01,\n",
       "       4.000e+03, 1.650e+02, 5.800e+01, 1.100e+02, 9.900e+01, 8.000e+01,\n",
       "       1.050e+02, 7.600e+01, 1.650e+02, 1.100e+02, 4.000e+03, 9.200e+01,\n",
       "       1.240e+02, 3.000e+02, 1.000e+02, 8.000e+02, 1.510e+02, 4.000e+02,\n",
       "       1.350e+02, 1.300e+02, 1.000e+02, 8.200e+01, 6.500e+01, 8.300e+01,\n",
       "       9.700e+01, 1.100e+02, 6.600e+01, 5.000e+01, 3.400e+02, 5.100e+01,\n",
       "       7.000e+01, 1.330e+02, 1.250e+02, 3.000e+02, 1.100e+02, 8.000e+01,\n",
       "       1.000e+03, 2.250e+02, 2.900e+02])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model Training and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def embedding_layer(ids_, V, embed_dim, init_scale=0.001):\n",
    "    \n",
    "    W_embed_ = tf.get_variable(name = \"W_embed\", shape = [V, embed_dim],\n",
    "    initializer = tf.random_uniform_initializer( minval = -init_scale, maxval = init_scale))                 \n",
    "    xs_ = tf.nn.embedding_lookup(W_embed_, ids_)\n",
    "\n",
    "    return xs_\n",
    "\n",
    "def fully_connected_layers(h0_, hidden_dims, activation=tf.tanh,\n",
    "                           dropout_rate=0, is_training=False):\n",
    "    h_ = h0_\n",
    "    for i, hdim in enumerate(hidden_dims):\n",
    "        h_ = tf.layers.dense(h_, hdim, activation=activation, name=(\"Hidden_%d\"%i))\n",
    "\n",
    "        if dropout_rate > 0:\n",
    "            h_ =  tf.layers.dropout(h_, rate=dropout_rate)\n",
    "\n",
    "    return h_\n",
    "\n",
    "def output_layer(h_, labels_, num_classes):\n",
    "    with tf.variable_scope(\"Logits\"):\n",
    "\n",
    "        W_out_ = tf.get_variable(name = \"W_out\", shape=[h_.shape[1], num_classes], initializer = tf.random_normal_initializer())\n",
    "        b_out_ = tf.get_variable(\"b_out\", shape = [num_classes], initializer=tf.zeros_initializer())\n",
    "        logits_ = tf.add(tf.matmul(h_, W_out_), b_out_) \n",
    "        predictions_ = tf.squeeze(logits_, 1)\n",
    "\n",
    "        \n",
    "    if labels_ is None:\n",
    "        return None, logits_, W_out_\n",
    "\n",
    "    with tf.name_scope(\"RMSE\"):\n",
    "        loss_ = tf.losses.mean_squared_error(labels = labels_, predictions = predictions_)\n",
    "\n",
    "        \n",
    "    return loss_, logits_, W_out_\n",
    "\n",
    "\n",
    "\n",
    "def BOW_encoder(ids_, ns_, V, embed_dim, hidden_dims, dropout_rate=0,\n",
    "                is_training=None,\n",
    "                **unused_kw):\n",
    "    assert is_training is not None, \"is_training must be explicitly set to True or False\"\n",
    " \n",
    "    with tf.variable_scope(\"Embedding_Layer\"):\n",
    "        xs_ = embedding_layer(ids_, V, embed_dim, init_scale=0.001)\n",
    "\n",
    "    mask_ = tf.expand_dims(tf.sequence_mask(ns_, xs_.shape[1], dtype=tf.float32),-1)\n",
    "\n",
    "    sum_e = tf.reduce_sum(xs_*mask_, 1)\n",
    "\n",
    "    h_ = fully_connected_layers(sum_e, hidden_dims, activation=tf.tanh,\n",
    "            dropout_rate=dropout_rate, is_training=is_training)\n",
    "\n",
    "    return h_, xs_\n",
    "\n",
    "\n",
    "def classifier_model_fn(features, labels, mode, params):\n",
    "    tf.set_random_seed(params.get('rseed', 10))\n",
    "\n",
    "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    if params['encoder_type'] == 'bow':\n",
    "        with tf.variable_scope(\"Encoder\"):\n",
    "            h_, xs_ = BOW_encoder(features['ids'], features['ns'],\n",
    "                                  is_training=is_training,\n",
    "                                  **params)\n",
    "    else:\n",
    "        raise ValueError(\"Error: unsupported encoder type \"\n",
    "                         \"'{:s}'\".format(params['encoder_type']))\n",
    "\n",
    "    with tf.variable_scope(\"Output_Layer\"):\n",
    "        ce_loss_, logits_, W_out_ = output_layer(h_, labels ,params['num_classes'] )\n",
    "\n",
    "    with tf.name_scope(\"Prediction\"):\n",
    "        \n",
    "        pred_max_ = tf.squeeze(logits_, 1)\n",
    "        \n",
    "        predictions_dict = {\"proba\": logits_, \"max\": pred_max_}\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions=predictions_dict)\n",
    "\n",
    "    with tf.variable_scope(\"Regularization\"):\n",
    "        l2_penalty_ = tf.nn.l2_loss(xs_)  \n",
    "        for var_ in tf.trainable_variables():\n",
    "            if \"Embedding_Layer\" in var_.name:\n",
    "                continue\n",
    "            l2_penalty_ += tf.nn.l2_loss(var_)\n",
    "        l2_penalty_ *= params['beta']  \n",
    "        tf.summary.scalar(\"l2_penalty\", l2_penalty_)\n",
    "        regularized_loss_ = ce_loss_ + l2_penalty_\n",
    "\n",
    "    with tf.variable_scope(\"Training\"):\n",
    "        if params['optimizer'] == 'adam':\n",
    "            optimizer_ = tf.train.AdamOptimizer(params['lr'])\n",
    "        else:\n",
    "            optimizer_ = tf.train.GradientDescentOptimizer(params['lr'])\n",
    "        train_op_ = optimizer_.minimize(ce_loss_,\n",
    "                                            global_step=tf.train.get_global_step())\n",
    "\n",
    "    tf.summary.scalar(\"cross_entropy_loss\", ce_loss_)\n",
    "    eval_metrics = {\"cross_entropy_loss\": tf.metrics.mean(ce_loss_),\n",
    "                    \"accuracy\": tf.metrics.accuracy(labels, pred_max_)}\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                      predictions=predictions_dict,\n",
    "                                      loss=regularized_loss_,\n",
    "                                      train_op=train_op_,\n",
    "                                      eval_metric_ops=eval_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary (16,474 words) written to '/tmp/tf_bow_sst_20180807-2337/metadata.tsv'\n",
      "Projector config written to /tmp/tf_bow_sst_20180807-2337/projector_config.pbtxt\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tf_bow_sst_20180807-2337', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f98604269b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "\n",
      "To view training (once it starts), run:\n",
      "\n",
      "    tensorboard --logdir='/tmp/tf_bow_sst_20180807-2337' --port 6006\n",
      "\n",
      "Then in your browser, open: http://localhost:6006\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_params = dict(V=vocabulary, embed_dim=50, hidden_dims=[25], num_classes = 1,\n",
    "                    encoder_type='bow',\n",
    "                    lr=0.1, optimizer='adam', beta=0.01)\n",
    "\n",
    "checkpoint_dir = \"/tmp/tf_bow_sst_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "if os.path.isdir(checkpoint_dir):\n",
    "    shutil.rmtree(checkpoint_dir)\n",
    "\n",
    "ds.vocab.write_projector_config(checkpoint_dir, \"Encoder/Embedding_Layer/W_embed\")\n",
    "\n",
    "model = tf.estimator.Estimator(model_fn= classifier_model_fn, \n",
    "                               params=model_params,\n",
    "                               model_dir=checkpoint_dir)\n",
    "print(\"\")\n",
    "print(\"To view training (once it starts), run:\\n\")\n",
    "print(\"    tensorboard --logdir='{:s}' --port 6006\".format(checkpoint_dir))\n",
    "print(\"\\nThen in your browser, open: http://localhost:6006\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:loss = 1960503.8, step = 1\n",
      "INFO:tensorflow:global_step/sec: 100.13\n",
      "INFO:tensorflow:loss = 900913.9, step = 101 (1.000 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 112 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 860525.56.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-07-23:37:49\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-112\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-07-23:37:49\n",
      "INFO:tensorflow:Saving dict for global step 112: accuracy = 0.0, cross_entropy_loss = 5929479.5, global_step = 112, loss = 5929887.5\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-112\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 113 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:loss = 1749438.0, step = 113\n",
      "INFO:tensorflow:global_step/sec: 89.9947\n",
      "INFO:tensorflow:loss = 853852.3, step = 213 (1.112 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 224 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 811072.56.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-07-23:37:52\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-224\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-07-23:37:52\n",
      "INFO:tensorflow:Saving dict for global step 224: accuracy = 0.0, cross_entropy_loss = 5825141.5, global_step = 224, loss = 5825562.5\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-224\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 225 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:loss = 1661614.9, step = 225\n",
      "INFO:tensorflow:global_step/sec: 102.03\n",
      "INFO:tensorflow:loss = 840446.56, step = 325 (0.981 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 336 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 794647.9.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-07-23:37:54\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-336\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-07-23:37:55\n",
      "INFO:tensorflow:Saving dict for global step 336: accuracy = 0.0, cross_entropy_loss = 5769121.0, global_step = 336, loss = 5769555.0\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-336\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 337 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:loss = 1617483.6, step = 337\n",
      "INFO:tensorflow:global_step/sec: 104.884\n",
      "INFO:tensorflow:loss = 841340.8, step = 437 (0.954 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 448 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 792726.2.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-07-23:37:57\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-448\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-07-23:37:57\n",
      "INFO:tensorflow:Saving dict for global step 448: accuracy = 0.0, cross_entropy_loss = 5739026.5, global_step = 448, loss = 5739471.5\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-448\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 449 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:loss = 1595832.5, step = 449\n",
      "INFO:tensorflow:global_step/sec: 106.935\n",
      "INFO:tensorflow:loss = 847143.25, step = 549 (0.936 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 560 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 796202.7.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-07-23:38:00\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-560\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-07-23:38:00\n",
      "INFO:tensorflow:Saving dict for global step 560: accuracy = 0.0, cross_entropy_loss = 5722732.0, global_step = 560, loss = 5723185.0\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-560\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 561 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:loss = 1585455.9, step = 561\n",
      "INFO:tensorflow:global_step/sec: 105.551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 853677.75, step = 661 (0.948 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 672 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 800945.94.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-07-23:38:03\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-672\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-07-23:38:03\n",
      "INFO:tensorflow:Saving dict for global step 672: accuracy = 0.0, cross_entropy_loss = 5713754.0, global_step = 672, loss = 5714213.5\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-672\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 673 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:loss = 1580580.4, step = 673\n",
      "INFO:tensorflow:global_step/sec: 105.999\n",
      "INFO:tensorflow:loss = 859368.75, step = 773 (0.945 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 784 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 805316.7.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-07-23:38:05\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-784\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-07-23:38:05\n",
      "INFO:tensorflow:Saving dict for global step 784: accuracy = 0.0, cross_entropy_loss = 5708680.5, global_step = 784, loss = 5709144.5\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-784\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 785 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:loss = 1578329.0, step = 785\n",
      "INFO:tensorflow:global_step/sec: 106.709\n",
      "INFO:tensorflow:loss = 863821.56, step = 885 (0.938 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 896 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 808824.75.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-07-23:38:08\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-896\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-07-23:38:08\n",
      "INFO:tensorflow:Saving dict for global step 896: accuracy = 0.0, cross_entropy_loss = 5705729.5, global_step = 896, loss = 5706197.0\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-896\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 897 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:loss = 1577307.0, step = 897\n",
      "INFO:tensorflow:global_step/sec: 105.698\n",
      "INFO:tensorflow:loss = 867113.7, step = 997 (0.947 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1008 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 811453.56.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-07-23:38:11\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-1008\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-07-23:38:11\n",
      "INFO:tensorflow:Saving dict for global step 1008: accuracy = 0.0, cross_entropy_loss = 5703960.5, global_step = 1008, loss = 5704430.0\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-1008\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1009 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:loss = 1576851.4, step = 1009\n",
      "INFO:tensorflow:global_step/sec: 102.746\n",
      "INFO:tensorflow:loss = 869467.5, step = 1109 (0.974 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1120 into /tmp/tf_bow_sst_20180807-2337/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 813348.25.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-07-23:38:13\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-1120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-07-23:38:13\n",
      "INFO:tensorflow:Saving dict for global step 1120: accuracy = 0.0, cross_entropy_loss = 5702872.0, global_step = 1120, loss = 5703343.0\n"
     ]
    }
   ],
   "source": [
    "train_params = dict(batch_size=32, total_epochs=20, eval_every=2)\n",
    "assert(train_params['total_epochs'] % train_params['eval_every'] == 0)\n",
    "\n",
    "train_input_fn = patched_numpy_io.numpy_input_fn(\n",
    "                    x={\"ids\": train_x, \"ns\": train_ns}, y=train_y,\n",
    "                    batch_size=train_params['batch_size'], \n",
    "                    num_epochs=train_params['eval_every'], shuffle=True, seed=42\n",
    "                 )\n",
    "\n",
    "\n",
    "dev_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "                    x={\"ids\": dev_x, \"ns\": dev_ns}, y=dev_y,\n",
    "                    batch_size=128, num_epochs=1, shuffle=False\n",
    "                )\n",
    "\n",
    "for _ in range(train_params['total_epochs'] // train_params['eval_every']):\n",
    "    model.train(input_fn=train_input_fn)\n",
    "    eval_metrics = model.evaluate(input_fn=dev_input_fn, name=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-07-23:38:14\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-1120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-07-23:38:14\n",
      "INFO:tensorflow:Saving dict for global step 1120: accuracy = 0.0, cross_entropy_loss = 276659.16, global_step = 1120, loss = 277314.16\n",
      "Accuracy on test set: 0.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.0,\n",
       " 'cross_entropy_loss': 276659.16,\n",
       " 'global_step': 1120,\n",
       " 'loss': 277314.16}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "                    x={\"ids\": test_x, \"ns\": test_ns}, y=test_y,\n",
    "                    batch_size=128, num_epochs=1, shuffle=False)\n",
    "\n",
    "\n",
    "eval_metrics = model.evaluate(input_fn=test_input_fn, name=\"test\") \n",
    "eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "Predictions Tensor(\"Output_Layer/Logits/Squeeze:0\", shape=(?,), dtype=float32)\n",
      "Logits:  Tensor(\"Output_Layer/Logits/Add:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_bow_sst_20180807-2337/model.ckpt-1120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = list(model.predict(test_input_fn)) \n",
    "y_pred = [p['max'] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  85.,   90.,  113.,  690.,  110.,  120.,   55.,  170.,  170.,\n",
       "        180.,   60.,   50.,   85.,   88.,  117.,  138.,   84.,   85.,\n",
       "        150.,   45.,  265.,  135.,  140.,  155.,  160.,  100.,   73.,\n",
       "        160.,  210.,  592.,  125.,   36.,   90.,  155.,  900.,   50.,\n",
       "        100.,  156.,  700.,   89.,   67.,   73.,  440.,   51.,   90.,\n",
       "         93.,  111.,  130.,   45.,   49.,  220.,   80.,  137.,   76.,\n",
       "         75.,   65.,  121.,  190.,   70.,   44.,   90., 2750.,   70.,\n",
       "         56.,  567.,  185.,   63.,   97.,   70.,   40.,   40.,   73.,\n",
       "         55.,  180.,   70.,   65.,   30.,   70.,  119.,  154.,  164.,\n",
       "        104.,  190.,   54.,  125.,   60.,  108.,   78.,   40.,  325.,\n",
       "        100.,   90.,   45.,   61.,   61.,   46.,  119.,  160.,  100.,\n",
       "        142.,   77.,   32.,   98.,   60.,  168.,  119.,   73.,   69.,\n",
       "        110.,   90.,   90.,   95.,   72.,   73.,   76.,   37.,   33.,\n",
       "         44.,   53.,   65.,  348.,   61.,  115.,  126.,   60.,  195.,\n",
       "         69.,   22.,   40.,   55.,  700.,  212.,   90.,  101.,   75.,\n",
       "         50.,  150.,   88.,  465.,   65.,   75.,   60., 1250.,  135.,\n",
       "        100.,   72.,   55.,   32.,  180.,   90.,   65.,  125.,   65.,\n",
       "         56.,  288.,   55.,   72.,   84.,   44.,   90.,  150.,   65.,\n",
       "         60.,  151.,   73.,   73.,   70.,  115.,  100.,   59.,   52.,\n",
       "         48.,   59.,  100.,   65.,  120.,  124.,   53.,   65.,  200.,\n",
       "         80.,  100.,  100.,   30.,  200.,  100.,   42.,   50.,   70.,\n",
       "         65.,   70.,   70.,   40.,   40.,   55.,   30.,   55.,   58.,\n",
       "         52.,  157.,   91.,   64.,   18.,   15.,   67.,  130.,   56.,\n",
       "        101.,   88.,  191.,  100.,  206.,   35.,   73.,  135.,   50.,\n",
       "         25.,   17.,  145.,   40.,  126.,  185.,  200.,   45.,   33.,\n",
       "        145.,   35.,   80.,  160.,  153.,  140.,   65.,   65.,  135.,\n",
       "         84.,  109.,  210.,   93.,  115.,  175.,   45.,   60.,  899.,\n",
       "        109.,   60.,  238.,   63.,   55.,   80.,   70.,  138.,   80.,\n",
       "         75.,   25.,  133.,   90.,  125.,  170.,  135.,  300.,  155.,\n",
       "         67.,   75.,   52.,   40.,  112.,   53.,   78.,   82.,   61.,\n",
       "         60.,  239.,   80.,   21.,  134.,  340.,   14.,   12.,   53.,\n",
       "         75.,  155.,  146.,  108.,   56.,  117.,   82.,   98.,  109.,\n",
       "        120.,   95.,   50.,   70.,   40.,   70.,   30.,  130.,  576.,\n",
       "       1800.,   63.,   82.,   93.,  102.,   80.,   85.,   94.,  160.,\n",
       "        123.,   57.,   81.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514,\n",
       " 608.3514]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
